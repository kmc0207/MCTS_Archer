cache_dir: '/home/yifei/.cache'

wandb_key: ""
huggingface_token: ""
policy_lm: "gpt2"
critic_lm: "roberta-base"
use_baseline: False
use_lora: False
max_new_tokens: 32
save_freq: 25
eval_freq: 5

#training hyperparameters
capacity: 100000 #replay buffer size
rollout_size: 60 #number of rollout trajectories for each update
bc_rollout_size: 30
eval_size: 16 #number of trajectories for evaluation
batch_size: 30
iterations: 2000 #total number of iterations
epochs: 50 #number of epochs for the critic each iteration
actor_epochs: 2  #number of epochs for the actor each iteration
bc_epochs: 2
warmup_iter: 1.0 #number of iterations without updating the policy
grad_accum_steps: 32
do_sample: True
temperature: 1.0
critic_lr: 1e-5
lm_lr: 1e-6
env_idx: null #set to null if don't want to reset to a specific environment
gamma: 0.95 #discount factor
tau: 0.1 #soft update parameter
max_grad_norm: 1.0
dpo_weight: 0.5
# checkpoint
agent_type: "online_filteredbc"

checkpoint_path: '../gpt2_bc_20q.pt'
save_path: '../outputs/gpu_1'
use_bfloat16: True
clear: False
use_ref: True
use_mix: True
update_ref: True
update_term: 5
reward_filtering: False
bc_explore: True
one_split: False
bc_from_dpo: False
# env
env_name: twenty_questions
env_load_path: '../20q_t5_oracle.pt'

# wandb logging
use_wandb: True
project_name: 'dpo_naive_test_v2'
run_name: 'bc_from_dpo_ut3_gpu1'